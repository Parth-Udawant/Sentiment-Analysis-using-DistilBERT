
  

# 🧠 Sentiment Analysis with DistilBERT

  

This project fine-tunes a DistilBERT transformer model on the Amazon Reviews dataset to classify text into **positive** or **negative** sentiment. Built using Hugging Face Transformers and PyTorch with optional GPU acceleration.

Dataset Used: https://www.kaggle.com/datasets/bittlingmayer/amazonreviews

  

## 🚀 Features

  

- ✅ Binary sentiment classification (Positive / Negative)

- 📦 Fine-tuned on Amazon Reviews dataset

- 🧠 Uses Hugging Face `DistilBERT` and `Trainer` API

- ⚡ GPU support for accelerated training

- 🔍 Real-world review testing using inference pipeline

- 📊 Accuracy: ~92% on validation set

  

## 🛠️ Setup Instructions

  

```bash

1.  Clone  the  repository
git  clone  https://github.com/parthudawant/sentiment-analysis-using-distilbert.git
cd  sentiment-analysis-using-distilbert

2.  Install  dependencies
pip  install  -r  requirements.txt

```

  

## ✍️ Author

  

[![Instagram](https://img.shields.io/badge/Instagram-%40theidealcoder-E4405F?style=flat-square&logo=instagram&logoColor=white)](https://www.instagram.com/theidealcoder)
[![GitHub](https://img.shields.io/badge/GitHub-ParthUdawant-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/ParthUdawant)

  

Made with ❤️ by **Parth Udawant**