
  

# ğŸ§  Sentiment Analysis with DistilBERT

  

This project fine-tunes a DistilBERT transformer model on the Amazon Reviews dataset to classify text into **positive** or **negative** sentiment. Built using Hugging Face Transformers and PyTorch with optional GPU acceleration.

Dataset Used: https://www.kaggle.com/datasets/bittlingmayer/amazonreviews

  

## ğŸš€ Features

  

- âœ… Binary sentiment classification (Positive / Negative)

- ğŸ“¦ Fine-tuned on Amazon Reviews dataset

- ğŸ§  Uses Hugging Face `DistilBERT` and `Trainer` API

- âš¡ GPU support for accelerated training

- ğŸ” Real-world review testing using inference pipeline

- ğŸ“Š Accuracy: ~92% on validation set

  

## ğŸ› ï¸ Setup Instructions

  

```bash

1.  Clone  the  repository
git  clone  https://github.com/parthudawant/sentiment-analysis-using-distilbert.git
cd  sentiment-analysis-using-distilbert

2.  Install  dependencies
pip  install  -r  requirements.txt

```

  

## âœï¸ Author

  

[![Instagram](https://img.shields.io/badge/Instagram-%40theidealcoder-E4405F?style=flat-square&logo=instagram&logoColor=white)](https://www.instagram.com/theidealcoder)
[![GitHub](https://img.shields.io/badge/GitHub-ParthUdawant-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/ParthUdawant)

  

Made with â¤ï¸ by **Parth Udawant**